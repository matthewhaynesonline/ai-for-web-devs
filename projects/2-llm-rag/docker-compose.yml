services:
  web:
    container_name: chat_web
    build: app
    command: "python app.py"
    restart: unless-stopped
    env_file:
      - ./.env
    ports:
      - "${APP_PORT_HOST}:${APP_PORT}"
    volumes:
      - ./app:/usr/src/app
      - ./volumes/app/pip:/root/.cache/pip
      - ./volumes/app/pip3:/usr/local/lib/python3.12/site-packages
      - ./volumes/app/nltk_data:/root/nltk_data
    depends_on:
      chroma:
        condition: service_started
      infinity:
        condition: service_healthy
      ollama:
        condition: service_started

  chroma:
    container_name: chat_chroma
    image: chromadb/chroma:0.4.25.dev104
    restart: unless-stopped
    volumes:
      - ./volumes/chroma:/chroma/chroma
    environment:
      - ALLOW_RESET=TRUE
    ports:
      - "${CHROMA_PORT}:${CHROMA_PORT}"

  infinity:
    container_name: chat_infinity
    build:
      context: app_infinity
      args:
        MODEL: "${EMBEDDING_MODEL}"
        PORT: "${INFINITY_PORT}"
    restart: unless-stopped
    ports:
      - "${INFINITY_PORT}:${INFINITY_PORT}"
    healthcheck:
      test: "curl -f localhost:${INFINITY_PORT} || exit 1"
      interval: 60s
      retries: 5
      timeout: 10s

  ollama:
    container_name: chat_ollama
    image: ollama/ollama:0.1.30
    restart: unless-stopped
    volumes:
      - ./volumes/ollama:/root/.ollama
    ports:
      - "${OLLAMA_PORT_HOST}:${OLLAMA_PORT}"
